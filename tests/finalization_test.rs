// Copyright (c) 2025-2026 the ruley contributors
// SPDX-License-Identifier: Apache-2.0

//! Tests for the finalization pipeline.
//!
//! Tests post-processing (normalization), metadata injection, deconfliction
//! detection, and cost estimation for the finalization stage.

use ruley::generator::rules::{FormattedRules, GeneratedRules, GenerationMetadata};
use ruley::utils::finalization::{
    FinalizationResult, OptimizationResult, estimate_deconfliction_tokens,
};
use std::collections::HashMap;

mod normalization {
    use super::*;

    /// Test CRLF line endings are normalized to LF.
    #[test]
    fn test_crlf_normalization() {
        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "line1\r\nline2\r\nline3"));

        let content = rules.get_format("cursor").unwrap().content.clone();
        // Simulate normalize_content behavior
        let normalized = content.replace("\r\n", "\n").replace('\r', "\n");
        assert!(
            !normalized.contains("\r\n"),
            "CRLF should be converted to LF"
        );
        assert!(normalized.contains("line1\nline2\nline3"));
    }

    /// Test CR-only line endings are normalized.
    #[test]
    fn test_cr_normalization() {
        let content = "line1\rline2\rline3";
        let normalized = content.replace("\r\n", "\n").replace('\r', "\n");
        assert_eq!(normalized, "line1\nline2\nline3");
    }

    /// Test trailing whitespace is trimmed from each line.
    #[test]
    fn test_trailing_whitespace_trimmed() {
        let content = "line1   \nline2\t\nline3  ";
        let lines: Vec<&str> = content.lines().map(|l| l.trim_end()).collect();
        let normalized = lines.join("\n");
        assert_eq!(normalized, "line1\nline2\nline3");
    }

    /// Test trailing newline is ensured.
    #[test]
    fn test_trailing_newline_ensured() {
        let content = "line1\nline2";
        let mut normalized = content.to_string();
        if !normalized.ends_with('\n') {
            normalized.push('\n');
        }
        assert!(normalized.ends_with('\n'));
        assert_eq!(normalized, "line1\nline2\n");
    }

    /// Test already-normalized content is unchanged.
    #[test]
    fn test_already_normalized_unchanged() {
        let content = "line1\nline2\n";
        let normalized = content.replace("\r\n", "\n").replace('\r', "\n");
        let lines: Vec<&str> = normalized.lines().map(|l| l.trim_end()).collect();
        let mut result = lines.join("\n");
        if !result.ends_with('\n') {
            result.push('\n');
        }
        assert_eq!(result, "line1\nline2\n");
    }
}

mod metadata_injection {
    use super::*;

    /// Test metadata is injected into Markdown formats.
    #[test]
    fn test_metadata_injected_into_markdown() {
        let mut rules = GeneratedRules::new("analysis");
        rules.metadata =
            GenerationMetadata::new("anthropic", "claude-3-opus").with_usage(1000, 500, 0.05);
        rules.add_format(FormattedRules::new(
            "cursor",
            "# Cursor Rules\n\nUse spaces.",
        ));

        // Simulate metadata injection
        let version = env!("CARGO_PKG_VERSION");
        let metadata_comment = format!(
            "<!-- Generated by ruley v{} | {} | {}/{} | tokens: {}/{} | cost: ${:.4} -->",
            version,
            rules.metadata.timestamp,
            rules.metadata.provider,
            rules.metadata.model,
            rules.metadata.input_tokens,
            rules.metadata.output_tokens,
            rules.metadata.cost,
        );

        assert!(metadata_comment.contains("ruley v"));
        assert!(metadata_comment.contains("anthropic/claude-3-opus"));
        assert!(metadata_comment.contains("1000/500"));
        assert!(metadata_comment.contains("$0.0500"));
    }

    /// Test metadata is NOT injected into JSON format.
    #[test]
    fn test_metadata_skipped_for_json() {
        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("json", r#"{"rules":[]}"#));

        // JSON should not receive HTML comment metadata
        let format_name = "json";
        let should_inject = format_name != "json";
        assert!(!should_inject, "JSON format should skip metadata injection");
    }

    /// Test metadata includes all required fields.
    #[test]
    fn test_metadata_contains_all_fields() {
        let metadata = GenerationMetadata::new("openai", "gpt-4o").with_usage(2000, 800, 0.10);

        assert_eq!(metadata.provider, "openai");
        assert_eq!(metadata.model, "gpt-4o");
        assert_eq!(metadata.input_tokens, 2000);
        assert_eq!(metadata.output_tokens, 800);
        assert!((metadata.cost - 0.10).abs() < f64::EPSILON);
        assert!(!metadata.timestamp.is_empty());
    }
}

mod deconfliction {
    use super::*;

    /// Test deconfliction token estimation.
    #[test]
    fn test_deconfliction_token_estimation() {
        let mut existing = HashMap::new();
        existing.insert("CLAUDE.md".to_string(), "x".repeat(400));
        existing.insert(".windsurfrules".to_string(), "y".repeat(400));

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "z".repeat(400)));

        let tokens = estimate_deconfliction_tokens(&existing, &rules);
        // (800 + 400) / 4 = 300
        assert_eq!(tokens, 300);
    }

    /// Test deconfliction token estimation with multiple formats.
    #[test]
    fn test_deconfliction_tokens_multiple_formats() {
        let mut existing = HashMap::new();
        existing.insert("CLAUDE.md".to_string(), "a".repeat(1000));

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "b".repeat(500)));
        rules.add_format(FormattedRules::new("claude", "c".repeat(500)));

        let tokens = estimate_deconfliction_tokens(&existing, &rules);
        // (1000 + 500 + 500) / 4 = 500
        assert_eq!(tokens, 500);
    }

    /// Test deconfliction token estimation with empty existing rules.
    #[test]
    fn test_deconfliction_tokens_no_existing() {
        let existing = HashMap::new();

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "a".repeat(400)));

        let tokens = estimate_deconfliction_tokens(&existing, &rules);
        // (0 + 400) / 4 = 100
        assert_eq!(tokens, 100);
    }
}

mod finalization_result {
    use super::*;

    /// Test FinalizationResult default values.
    #[test]
    fn test_finalization_result_defaults() {
        let result = FinalizationResult::default();
        assert!(!result.metadata_injected);
        assert!(!result.deconflicted);
        assert_eq!(result.optimizations.duplicates_removed, 0);
        assert_eq!(result.optimizations.rules_merged, 0);
        assert!(!result.optimizations.formatting_normalized);
    }

    /// Test OptimizationResult tracking.
    #[test]
    fn test_optimization_result() {
        let opt = OptimizationResult {
            duplicates_removed: 3,
            rules_merged: 2,
            formatting_normalized: true,
        };
        assert_eq!(opt.duplicates_removed, 3);
        assert_eq!(opt.rules_merged, 2);
        assert!(opt.formatting_normalized);
    }
}

// ── Comment 3: Finalization integration tests ──────────────────────────────

mod deconfliction_flow {
    use super::*;
    use tempfile::TempDir;

    /// Simulate existing rule files in a project directory and verify they are
    /// detected and counted correctly for deconfliction token estimation.
    #[test]
    fn test_existing_rule_files_detected_for_estimation() {
        let temp_dir = TempDir::new().unwrap();
        let project_path = temp_dir.path();

        // Create existing rule files matching KNOWN_RULE_FILE_NAMES
        std::fs::write(
            project_path.join("CLAUDE.md"),
            "# Existing Claude Rules\n\nUse spaces.\n",
        )
        .unwrap();
        std::fs::write(
            project_path.join(".windsurfrules"),
            "# Windsurf Rules\n\nBe consistent.\n",
        )
        .unwrap();

        // Replicate detection logic (detect_existing_rules is private)
        let known_files: &[&str] = &[
            "CLAUDE.md",
            ".windsurfrules",
            "CONVENTIONS.md",
            "AI_RULES.md",
            ".cursorrules",
        ];
        let mut existing = HashMap::new();
        for filename in known_files {
            let path = project_path.join(filename);
            if path.exists() {
                let content = std::fs::read_to_string(&path).unwrap();
                existing.insert(filename.to_string(), content);
            }
        }

        assert_eq!(existing.len(), 2, "Should detect 2 existing rule files");
        assert!(existing.contains_key("CLAUDE.md"));
        assert!(existing.contains_key(".windsurfrules"));
    }

    /// Test deconfliction token estimation accuracy with simulated existing files.
    #[test]
    fn test_deconfliction_estimation_with_real_file_content() {
        let claude_content = "# Rules\n\n".to_string() + &"x".repeat(200);
        let windsurf_content = "# Wind\n".to_string() + &"z".repeat(100);

        let mut existing = HashMap::new();
        existing.insert("CLAUDE.md".to_string(), claude_content.clone());
        existing.insert(".windsurfrules".to_string(), windsurf_content.clone());

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "y".repeat(300)));

        let tokens = estimate_deconfliction_tokens(&existing, &rules);
        let expected = (claude_content.len() + windsurf_content.len() + 300) / 4;
        assert_eq!(tokens, expected);
    }

    /// Test deconfliction prompt structure contains existing and generated content.
    #[test]
    fn test_deconfliction_prompt_contains_both_sources() {
        // build_deconfliction_prompt is private; verify structural expectations
        // The prompt wraps content in <existing_rules> and <generated_rules> tags
        let existing_content = "Use spaces for indentation.";
        let generated_content = "Use tabs for indentation.";

        // Build the same format the private function uses
        let prompt = format!(
            "<existing_rules>\n{}\n</existing_rules>\n\n<generated_rules>\n{}\n</generated_rules>",
            existing_content, generated_content
        );
        assert!(prompt.contains(existing_content));
        assert!(prompt.contains(generated_content));
        assert!(prompt.contains("<existing_rules>"));
        assert!(prompt.contains("<generated_rules>"));
    }

    /// Test .cursor/rules/ directory detection for existing .mdc files.
    #[test]
    fn test_cursor_rules_directory_detection() {
        let temp_dir = TempDir::new().unwrap();
        let project_path = temp_dir.path();

        // Create .cursor/rules/ directory with an .mdc file
        let cursor_dir = project_path.join(".cursor/rules");
        std::fs::create_dir_all(&cursor_dir).unwrap();
        std::fs::write(
            cursor_dir.join("project.mdc"),
            "---\ndescription: Existing\n---\n\n# Rules\n",
        )
        .unwrap();

        // Verify the directory and file exist
        assert!(cursor_dir.exists());
        let mdc_files: Vec<_> = std::fs::read_dir(&cursor_dir)
            .unwrap()
            .filter_map(|e| e.ok())
            .filter(|e| e.path().extension().is_some_and(|ext| ext == "mdc"))
            .collect();
        assert_eq!(mdc_files.len(), 1, "Should detect 1 existing .mdc file");
    }
}

mod cost_confirmation {
    use super::*;
    use ruley::cli::config::FinalizationConfig;
    use ruley::llm::cost::CostCalculator;
    use ruley::llm::provider::Pricing;

    /// Test cost estimation for deconfliction produces reasonable values.
    #[test]
    fn test_deconfliction_cost_estimation_accuracy() {
        let pricing = Pricing {
            input_per_1k: 0.003,
            output_per_1k: 0.015,
        };
        let calculator = CostCalculator::new(pricing);

        let mut existing = HashMap::new();
        existing.insert("CLAUDE.md".to_string(), "x".repeat(4000));

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "y".repeat(2000)));

        let input_tokens = estimate_deconfliction_tokens(&existing, &rules);
        let output_tokens = 500;
        let estimate = calculator.estimate_cost(input_tokens, output_tokens);

        assert!(
            estimate.total_cost > 0.0,
            "Cost should be positive for paid provider"
        );
        assert!(estimate.input_cost > 0.0);
        assert!(estimate.output_cost > 0.0);
    }

    /// Test FinalizationConfig defaults enable all finalization steps.
    #[test]
    fn test_finalization_config_defaults_enable_all() {
        let config = FinalizationConfig::default();
        assert!(config.enabled);
        assert!(config.deconflict);
        assert!(config.normalize_formatting);
        assert!(config.inject_metadata);
    }

    /// Test skip response should not perform deconfliction.
    #[test]
    fn test_skip_response_skips_deconfliction() {
        // When user responds 's' or 'skip' to cost confirmation,
        // deconflict_rules returns Ok(false) — no deconfliction performed
        let result = FinalizationResult::default();
        assert!(
            !result.deconflicted,
            "Skip response should leave deconflicted=false"
        );
    }

    /// Test cancel response error message.
    #[test]
    fn test_cancel_deconfliction_error_message() {
        // When user responds 'n' or anything other than y/s,
        // finalize_rules returns Err("User cancelled deconfliction")
        let error_msg = "User cancelled deconfliction";
        assert!(error_msg.contains("cancelled"));
        assert!(error_msg.contains("deconfliction"));
    }

    /// Test zero-cost provider (Ollama) deconfliction estimation.
    #[test]
    fn test_zero_cost_deconfliction_estimation() {
        let pricing = Pricing {
            input_per_1k: 0.0,
            output_per_1k: 0.0,
        };
        let calculator = CostCalculator::new(pricing);

        let mut existing = HashMap::new();
        existing.insert("CLAUDE.md".to_string(), "content".to_string());

        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("claude", "new content"));

        let tokens = estimate_deconfliction_tokens(&existing, &rules);
        let estimate = calculator.estimate_cost(tokens, tokens);

        assert!(
            (estimate.total_cost - 0.0).abs() < f64::EPSILON,
            "Zero-cost provider should have zero deconfliction cost"
        );
    }
}

mod no_deconflict_bypass {
    use ruley::cli::config::FinalizationConfig;
    use ruley::utils::finalization::FinalizationResult;

    /// Test --no-deconflict sets config flag correctly.
    #[test]
    fn test_no_deconflict_config_flag() {
        let mut config = FinalizationConfig::default();
        assert!(config.deconflict, "Default should enable deconfliction");

        // Simulate --no-deconflict CLI flag
        config.deconflict = false;
        assert!(
            !config.deconflict,
            "--no-deconflict should disable deconfliction"
        );
    }

    /// Test FinalizationResult reflects no deconfliction when disabled.
    #[test]
    fn test_result_reflects_no_deconfliction() {
        let result = FinalizationResult::default();
        assert!(
            !result.deconflicted,
            "Default result should show no deconfliction"
        );
    }

    /// Test disabled deconfliction still allows normalization and metadata.
    #[test]
    fn test_disabled_deconflict_preserves_other_steps() {
        let config = FinalizationConfig {
            enabled: true,
            deconflict: false,
            normalize_formatting: true,
            inject_metadata: true,
        };
        assert!(!config.deconflict);
        assert!(
            config.normalize_formatting,
            "Normalization should still be active"
        );
        assert!(
            config.inject_metadata,
            "Metadata injection should still be active"
        );
    }

    /// Test fully disabled finalization skips all steps.
    #[test]
    fn test_fully_disabled_finalization() {
        let config = FinalizationConfig {
            enabled: false,
            deconflict: true,
            normalize_formatting: true,
            inject_metadata: true,
        };
        assert!(!config.enabled, "Finalization should be fully disabled");
    }
}

mod deduplicated_outputs {
    use super::*;

    /// Test adding the same format twice replaces content (no duplicates).
    #[test]
    fn test_same_format_replaces_not_duplicates() {
        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "First content"));
        rules.add_format(FormattedRules::new("cursor", "Second content"));

        assert_eq!(
            rules.formats().count(),
            1,
            "Should have exactly one cursor format"
        );
        let content = rules.get_format("cursor").unwrap().content.clone();
        assert_eq!(content, "Second content", "Should have the latest content");
    }

    /// Test multiple distinct formats are maintained.
    #[test]
    fn test_multiple_formats_maintained() {
        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("cursor", "Cursor rules"));
        rules.add_format(FormattedRules::new("claude", "Claude rules"));
        rules.add_format(FormattedRules::new("copilot", "Copilot rules"));

        assert_eq!(rules.formats().count(), 3, "Should have 3 distinct formats");
    }

    /// Test all 7 formats can coexist without duplication.
    #[test]
    fn test_all_seven_formats_unique() {
        let mut rules = GeneratedRules::new("analysis");
        let formats = [
            "cursor", "claude", "copilot", "windsurf", "aider", "generic", "json",
        ];
        for format in &formats {
            rules.add_format(FormattedRules::new(*format, format!("# {} Rules", format)));
        }

        assert_eq!(rules.formats().count(), 7, "All 7 formats should be unique");

        // Adding a duplicate should not increase count
        rules.add_format(FormattedRules::new("cursor", "Updated cursor rules"));
        assert_eq!(
            rules.formats().count(),
            7,
            "Count should remain 7 after update"
        );
    }

    /// Test deduplicated outputs preserve the latest content for each format.
    #[test]
    fn test_deduplication_preserves_latest() {
        let mut rules = GeneratedRules::new("analysis");
        rules.add_format(FormattedRules::new("claude", "Version 1"));
        rules.add_format(FormattedRules::new("claude", "Version 2"));
        rules.add_format(FormattedRules::new("claude", "Version 3"));

        let content = rules.get_format("claude").unwrap().content.clone();
        assert_eq!(content, "Version 3", "Should keep most recent version");
    }
}

mod post_finalize_validation {
    use super::*;
    use ruley::cli::config::SemanticValidationConfig;
    use ruley::packer::{CodebaseMetadata, CompressedCodebase, CompressedFile, CompressionMethod};
    use ruley::utils::validation::{ValidationLayer, get_validator};
    use std::path::PathBuf;

    fn minimal_codebase() -> CompressedCodebase {
        CompressedCodebase {
            files: vec![CompressedFile {
                path: PathBuf::from("src/main.rs"),
                original_content: "fn main() {}".to_string(),
                compressed_content: "fn main() {}".to_string(),
                compression_method: CompressionMethod::None,
                original_size: 12,
                compressed_size: 12,
                language: None,
            }],
            metadata: CodebaseMetadata {
                total_files: 1,
                total_original_size: 12,
                total_compressed_size: 12,
                languages: HashMap::new(),
                compression_ratio: 1.0,
            },
        }
    }

    /// Test normalized content (CRLF → LF) passes syntax validation.
    #[test]
    fn test_normalized_content_passes_syntax() {
        let raw = "# Rules\r\n\r\n## Standards\r\n\r\nUse spaces.\r\n";
        let normalized = raw.replace("\r\n", "\n");

        let validator = get_validator("claude").unwrap();
        let codebase = minimal_codebase();
        let config = SemanticValidationConfig::default();

        let result = validator.validate(&normalized, &config, &codebase).unwrap();
        assert!(
            result.passed,
            "Normalized content should pass syntax: {:?}",
            result.errors
        );
    }

    /// Test metadata-injected content passes schema validation.
    #[test]
    fn test_metadata_injected_passes_schema() {
        let metadata_comment = "<!-- Generated by ruley v0.1.0 | 2024-01-01T00:00:00Z | anthropic/claude-3-opus | tokens: 1000/500 | cost: $0.0500 -->";
        let content = format!(
            "{}\n# Rules\n\n## Standards\n\nUse spaces.\n",
            metadata_comment
        );

        let validator = get_validator("claude").unwrap();
        let codebase = minimal_codebase();
        let config = SemanticValidationConfig::default();

        let result = validator.validate(&content, &config, &codebase).unwrap();
        assert!(
            result.passed,
            "Metadata-injected content should pass: {:?}",
            result.errors
        );
    }

    /// Test content with nonexistent file path triggers semantic validation.
    #[test]
    fn test_nonexistent_file_path_semantic_check() {
        let content = "# Rules\n\nSee `src/nonexistent_file.rs` for details.\n";

        let validator = get_validator("claude").unwrap();
        let codebase = minimal_codebase();
        let config = SemanticValidationConfig {
            check_file_paths: true,
            check_contradictions: false,
            check_consistency: false,
            check_reality: false,
        };

        let result = validator.validate(content, &config, &codebase).unwrap();
        // Semantic file path check should flag or warn about nonexistent path
        if !result.passed {
            assert!(
                result
                    .errors
                    .iter()
                    .any(|e| e.layer == ValidationLayer::Semantic),
                "File path error should be in semantic layer"
            );
        }
    }

    /// Test content with contradictions fails semantic validation post-finalize.
    #[test]
    fn test_contradictions_fail_post_finalize() {
        let content =
            "# Rules\n\nAlways use tabs for indentation.\nAlways use spaces for indentation.\n";

        let validator = get_validator("generic").unwrap();
        let codebase = minimal_codebase();
        let config = SemanticValidationConfig {
            check_contradictions: true,
            check_file_paths: false,
            check_consistency: false,
            check_reality: false,
        };

        let result = validator.validate(content, &config, &codebase).unwrap();
        assert!(
            result
                .errors
                .iter()
                .any(|e| e.layer == ValidationLayer::Semantic),
            "Should detect contradiction between tabs and spaces"
        );
    }

    /// Test post-finalize validation passes for clean content across all formats.
    #[test]
    fn test_clean_content_passes_all_format_validation() {
        let codebase = minimal_codebase();
        let config = SemanticValidationConfig::default();

        let test_cases = [
            ("claude", "# Rules\n\n## Standards\n\nUse spaces.\n"),
            (
                "copilot",
                "# Copilot Instructions\n\nUse consistent naming.\n",
            ),
            ("windsurf", "# Windsurf Rules\n\nFollow conventions.\n"),
            ("aider", "# Conventions\n\nUse consistent formatting.\n"),
            ("generic", "# AI Rules\n\nUse proper indentation.\n"),
            ("json", r#"{"rules": ["Use consistent formatting"]}"#),
        ];

        for (format, content) in &test_cases {
            let validator = get_validator(format).unwrap();
            let result = validator.validate(content, &config, &codebase).unwrap();
            assert!(
                result.passed,
                "Post-finalize {} content should pass: {:?}",
                format, result.errors
            );
        }
    }
}
